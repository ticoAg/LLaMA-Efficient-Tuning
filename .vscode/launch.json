{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: 当前文件",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": true
        },
        {
            "name": "debug train gpt2",
            "type": "debugpy",
            "request": "launch",
            "program": "src/train_bash.py",
            "console": "integratedTerminal",
            "args": [
                "--stage",
                "pt",
                "--model_name_or_path",
                "/home/tico/models/gpt2-tigerbot-pt-zh",
                "--do_train",
                "--finetuning_type",
                "full",
                "--dataset",
                "wiki_demo",
                "--template",
                "ziya",
                "--use_fast_tokenizer",
                "--preprocessing_num_workers",
                "1",
                "--per_device_train_batch_size",
                "2",
                "--gradient_accumulation_steps",
                "2",
                "--output_dir",
                ".cache/gpt2-pt-test",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "5",
                "--save_steps",
                "100",
                "--eval_steps",
                "500",
                "--learning_rate",
                "1e-5",
                "--num_train_epochs",
                "3.0",
                "--val_size",
                "200",
                "--evaluation_strategy",
                "steps",
                "--plot_loss",
                "--max_length",
                "1024",
                "--bf16"
            ]
        },
        {
            "name": "debug train rm",
            "type": "debugpy",
            "request": "launch",
            "program": "src/train_bash.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--stage",
                "rm",
                "--model_name_or_path",
                "ticoAg/gpt2-tiger-sft-zh",
                "--overwrite_output_dir",
                "--do_train",
                "--finetuning_type",
                "full",
                "--preprocessing_num_workers",
                "4",
                "--dataset",
                "comparison_gpt4_zh",
                "--num_train_epochs",
                "1",
                "--template",
                "ziya",
                "--use_fast_tokenizer",
                "--per_device_train_batch_size",
                "2",
                "--per_device_eval_batch_size",
                "2",
                "--gradient_accumulation_steps",
                "2",
                "--output_dir",
                ".cache/gpt2-tiger-zh-sft-rm",
                "--lr_scheduler_type",
                "cosine",
                "--val_size",
                "10",
                "--logging_steps",
                "1",
                "--save_steps",
                "0.5",
                "--max_samples",
                "100",
                "--warmup_ratio",
                "0.1",
                "--learning_rate",
                "1e-5",
                "--max_grad_norm",
                "0.5",
                "--adam_epsilon",
                "5e-7",
                "--plot_loss",
                "--run_name",
                "gpt2-tiger-zh-sft-rm",
                "--bf16"
            ]
        },
        {
            "name": "debug train ppo",
            "type": "debugpy",
            "request": "launch",
            "program": "src/train_bash.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--stage",
                "ppo",
                "--model_name_or_path",
                "ticoAg/gpt2-tiger-sft-zh",
                "--overwrite_output_dir",
                "--do_train",
                "--finetuning_type",
                "full",
                // "--lora_target", "c_proj",
                "--preprocessing_num_workers",
                "4",
                "--dataset",
                "alpaca_gpt4_zh",
                "--num_train_epochs",
                "3",
                "--template",
                "ziya",
                "--use_fast_tokenizer",
                "--per_device_train_batch_size",
                "2",
                "--per_device_eval_batch_size",
                "2",
                "--gradient_accumulation_steps",
                "1",
                "--reward_model",
                ".cache/gpt2-tiger-zh-sft-rm",
                "--output_dir",
                ".cache/gpt2-tiger-zh-sft-ppo",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "1",
                "--save_steps",
                "0.5",
                "--warmup_ratio",
                "0.1",
                "--learning_rate",
                "1e-5",
                "--run_name",
                "gpt2-tiger-zh-sft-ppo",
                "--plot_loss",
                "--bf16"
            ]
        },
        {
            "name": "debug infer gpt2",
            "type": "debugpy",
            "request": "launch",
            "program": "src/web_demo.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model_name_or_path",
                "ticoAg/gpt2-tiger-sft-zh",
                "--template",
                "baichuan"
            ]
        },
        {
            "name": "debug train qwen14",
            "type": "debugpy",
            "request": "launch",
            "program": "src/train_bash.py",
            "console": "integratedTerminal",
            "env": {
                "USE_MODELSCOPE_HUB": "1",
                "WANDB_PROJECT": "DPO",
                "WANDB_MODE": "disabled",
                "HF_ENDPOINT": "https://hf-mirror.com",
                "HF_TOKEN": "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",
                "http_proxy": "http://127.0.0.1:7890",
                "HTTP_PROXY": "http://127.0.0.1:7890",
                "https_proxy": "http://127.0.0.1:7890",
                "HTTPS_PROXY": "http://127.0.0.1:7890",
                "all_proxy": "http://127.0.0.1:7890",
                "ALL_PROXY": "http://127.0.0.1:7890",
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                "--stage", "sft",
                "--do_train",
                "--model_name_or_path", "qwen/Qwen1.5-14B",
                "--dataset", "sharegpt_hyper",
                "--max_samples", "10000",
                "--dataset_dir", "./data",
                "--tokenized_path", ".cache/ds/qwen1.5-14B-sft-v1",
                "--template", "qwen",
                "--finetuning_type", "lora",
                "--lora_target", "q_proj,v_proj",
                "--output_dir", ".cache/Align-Exp/qwen1.5-14B-sft-v1",
                "--use_fast_tokenizer", 
                "--overwrite_output_dir", 
                "--cutoff_len", "4096",
                "--preprocessing_num_workers", "1",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size", "2",
                "--gradient_accumulation_steps", "32",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "5",
                "--save_steps", "600",
                "--eval_steps", "600",
                "--evaluation_strategy", "steps",
                "--load_best_model_at_end", 
                "--learning_rate", "5e-5",
                "--lr_scheduler_type", "cosine",
                "--num_train_epochs", "1",
                "--warmup_ratio", "0.1",
                "--val_size", "2000",
                "--save_total_limit", "1",
                "--bf16", 
                "--report_to", "wandb",
                "--run_name", "qwen1.5-14B-sft-v1",
            ]
        },
    ]
}